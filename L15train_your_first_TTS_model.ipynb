{"cells":[{"cell_type":"markdown","id":"f79d99ef","metadata":{"id":"f79d99ef"},"source":["# Train your first 🐸 TTS model 💫\n","\n","### 👋 Hello and welcome to Coqui (🐸) TTS\n","\n","The goal of this notebook is to show you a **typical workflow** for **training** and **testing** a TTS model with 🐸.\n","\n","Let's train a very small model on a very small amount of data so we can iterate quickly.\n","\n","In this notebook, we will:\n","\n","1. Download data and format it for 🐸 TTS.\n","2. Configure the training and testing runs.\n","3. Train a new model.\n","4. Test the model and display its performance.\n","\n","So, let's jump right in!\n"]},{"cell_type":"code","execution_count":1,"id":"fa2aec78","metadata":{"id":"fa2aec78","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1697363729273,"user_tz":-330,"elapsed":106655,"user":{"displayName":"VARUN CHINDAGE (RA2111047010224)","userId":"15052075973333773834"}},"outputId":"fbf6201f-3399-4b8d-bc67-b87b3fbf21c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Collecting pip\n","  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.1.2\n","    Uninstalling pip-23.1.2:\n","      Successfully uninstalled pip-23.1.2\n","Successfully installed pip-23.2.1\n","Collecting TTS\n","  Obtaining dependency information for TTS from https://files.pythonhosted.org/packages/67/bf/c3fb7b77c74335a8932f003c1fd8db1bca9ae9328d2951e107207fa7b8fa/TTS-0.17.8-cp310-cp310-manylinux1_x86_64.whl.metadata\n","  Downloading TTS-0.17.8-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\n","Collecting cython==0.29.30 (from TTS)\n","  Downloading Cython-0.29.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.11.3)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.1+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.2+cu118)\n","Requirement already satisfied: soundfile==0.12.* in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n","Requirement already satisfied: librosa==0.10.* in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.1)\n","Collecting scikit-learn==1.3.0 (from TTS)\n","  Obtaining dependency information for scikit-learn==1.3.0 from https://files.pythonhosted.org/packages/5c/e9/ee572691a3fb05555bcde41826faad29ae4bc1fb07982e7f53d54a176879/scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Collecting inflect==5.6.* (from TTS)\n","  Downloading inflect-5.6.2-py3-none-any.whl (33 kB)\n","Collecting tqdm==4.64.* (from TTS)\n","  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting anyascii==0.3.* (from TTS)\n","  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml==6.* in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0.1)\n","Requirement already satisfied: fsspec==2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n","Requirement already satisfied: aiohttp==3.8.* in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.6)\n","Collecting packaging==23.1 (from TTS)\n","  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flask==2.* in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n","Collecting pysbd==0.3.4 (from TTS)\n","  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting umap-learn==0.5.* (from TTS)\n","  Downloading umap-learn-0.5.4.tar.gz (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.8/90.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n","Requirement already satisfied: matplotlib==3.7.* in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n","Collecting trainer (from TTS)\n","  Obtaining dependency information for trainer from https://files.pythonhosted.org/packages/14/93/32ab47a46633c889b5980a6525e4dd74e2bc71864d8498bd9c6e1233b8b0/trainer-0.0.31-py3-none-any.whl.metadata\n","  Downloading trainer-0.0.31-py3-none-any.whl.metadata (8.1 kB)\n","Collecting coqpit>=0.0.16 (from TTS)\n","  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n","Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n","Collecting pypinyin (from TTS)\n","  Obtaining dependency information for pypinyin from https://files.pythonhosted.org/packages/00/fc/3e82bf38739a7b2c4f699245ce6c84ff254723c678c2cdc5d2ecbddf9afb/pypinyin-0.49.0-py2.py3-none-any.whl.metadata\n","  Downloading pypinyin-0.49.0-py2.py3-none-any.whl.metadata (12 kB)\n","Collecting gruut[de,es,fr]==2.2.3 (from TTS)\n","  Downloading gruut-2.2.3.tar.gz (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting jamo (from TTS)\n","  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n","Collecting g2pkk>=0.1.1 (from TTS)\n","  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n","Collecting bangla (from TTS)\n","  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n","Collecting bnnumerizer (from TTS)\n","  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting bnunicodenormalizer (from TTS)\n","  Downloading bnunicodenormalizer-0.1.6.tar.gz (39 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting k-diffusion (from TTS)\n","  Obtaining dependency information for k-diffusion from https://files.pythonhosted.org/packages/de/d9/67ebd9d6ce9e65747e720c4c5614cd3a137e61340aec274657fcd9cc5162/k_diffusion-0.1.1-py3-none-any.whl.metadata\n","  Downloading k_diffusion-0.1.1-py3-none-any.whl.metadata (3.9 kB)\n","Collecting einops==0.6.* (from TTS)\n","  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers==4.33.* (from TTS)\n","  Obtaining dependency information for transformers==4.33.* from https://files.pythonhosted.org/packages/98/46/f6a79f944d5c7763a9bc13b2aa6ac72daf43a6551f5fb03bccf0a9c2fec1/transformers-4.33.3-py3-none-any.whl.metadata\n","  Downloading transformers-4.33.3-py3-none-any.whl.metadata (119 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting encodec==0.1.* (from TTS)\n","  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting unidecode==1.3.* (from TTS)\n","  Obtaining dependency information for unidecode==1.3.* from https://files.pythonhosted.org/packages/e4/63/7685ef40c65aba621ccd2524a24181bf11f0535ab1fdba47e40738eacff6/Unidecode-1.3.7-py3-none-any.whl.metadata\n","  Downloading Unidecode-1.3.7-py3-none-any.whl.metadata (13 kB)\n","Collecting numpy==1.22.0 (from TTS)\n","  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numba==0.57.0 (from TTS)\n","  Downloading numba-0.57.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.*->TTS) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.*->TTS) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.*->TTS) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.*->TTS) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.*->TTS) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.*->TTS) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.*->TTS) (1.3.1)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask==2.*->TTS) (3.0.0)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask==2.*->TTS) (3.1.2)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask==2.*->TTS) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask==2.*->TTS) (8.1.7)\n","Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.13.0)\n","Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gruut_lang_en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n","Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting num2words<1.0.0,>=0.5.10 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.*->TTS) (3.0.1)\n","INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n","Collecting librosa==0.10.* (from TTS)\n","  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading librosa-0.10.0.post1-py3-none-any.whl (252 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.*->TTS) (1.3.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.*->TTS) (4.4.2)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.*->TTS) (1.7.0)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.*->TTS) (0.3.7)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.*->TTS) (4.5.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.*->TTS) (0.3)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.*->TTS) (1.0.7)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.*->TTS) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.*->TTS) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.*->TTS) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.*->TTS) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.*->TTS) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.*->TTS) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.*->TTS) (2.8.2)\n","Collecting llvmlite<0.41,>=0.40.0dev0 (from numba==0.57.0->TTS)\n","  Obtaining dependency information for llvmlite<0.41,>=0.40.0dev0 from https://files.pythonhosted.org/packages/14/73/424ef49a4bb7bbc9c16f3fc66926cb3018699c69146cd130642c76ff2d97/llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->TTS) (3.2.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile==0.12.*->TTS) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.*->TTS) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers==4.33.*->TTS)\n","  Obtaining dependency information for huggingface-hub<1.0,>=0.15.1 from https://files.pythonhosted.org/packages/ef/b5/b6107bd65fa4c96fdf00e4733e2fe5729bb9e5e09997f63074bb43d3ab28/huggingface_hub-0.18.0-py3-none-any.whl.metadata\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.*->TTS) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.*->TTS) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.*->TTS)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.33.*->TTS)\n","  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/20/4e/878b080dbda92666233ec6f316a53969edcb58eab1aa399a64d0521cf953/safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting pynndescent>=0.5 (from umap-learn==0.5.*->TTS)\n","  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tbb>=2019.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.*->TTS) (2021.10.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS) (2023.3.post1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (1.12)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (17.0.2)\n","Collecting accelerate (from k-diffusion->TTS)\n","  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/d9/92/2d3aecf9f4a192968035880be3e2fc8b48d541c7128f7c936f430d6f96da/accelerate-0.23.0-py3-none-any.whl.metadata\n","  Downloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\n","Collecting clean-fid (from k-diffusion->TTS)\n","  Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n","Collecting clip-anytorch (from k-diffusion->TTS)\n","  Downloading clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dctorch (from k-diffusion->TTS)\n","  Obtaining dependency information for dctorch from https://files.pythonhosted.org/packages/cd/47/61b627404c2d6f31dcbc491ff83da1f4336c7ae7893cfdc6c52db490ec59/dctorch-0.1.2-py3-none-any.whl.metadata\n","  Downloading dctorch-0.1.2-py3-none-any.whl.metadata (607 bytes)\n","Collecting jsonmerge (from k-diffusion->TTS)\n","  Obtaining dependency information for jsonmerge from https://files.pythonhosted.org/packages/71/c2/1032d0dbc2152c45f3d1e582a72e68f41898de9665202392d9400dfa329d/jsonmerge-1.9.2-py3-none-any.whl.metadata\n","  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n","Collecting kornia (from k-diffusion->TTS)\n","  Obtaining dependency information for kornia from https://files.pythonhosted.org/packages/55/da/72cb83aa364ebb4d0109965e20c5d33d7063ccab15332c3fd0acfd5609c9/kornia-0.7.0-py2.py3-none-any.whl.metadata\n","  Downloading kornia-0.7.0-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.19.3)\n","Collecting torchdiffeq (from k-diffusion->TTS)\n","  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n","Collecting torchsde (from k-diffusion->TTS)\n","  Obtaining dependency information for torchsde from https://files.pythonhosted.org/packages/dd/1f/b67ebd7e19ffe259f05d3cf4547326725c3113d640c277030be3e9998d6f/torchsde-0.2.6-py3-none-any.whl.metadata\n","  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.15.2+cu118)\n","Collecting wandb (from k-diffusion->TTS)\n","  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/1c/5e/0362fa88679852c7fd3ac85ee5bd949426c4a51a61379010d4089be6d7ac/wandb-0.15.12-py3-none-any.whl.metadata\n","  Downloading wandb-0.15.12-py3-none-any.whl.metadata (9.8 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer->TTS) (5.9.5)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer->TTS) (2.13.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile==0.12.*->TTS) (2.21)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (5.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask==2.*->TTS) (2.1.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n","Collecting docopt>=0.6.2 (from num2words<1.0.0,>=0.5.10->gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.10.*->TTS) (3.11.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.*->TTS) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.*->TTS) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.*->TTS) (2023.7.22)\n","Collecting ftfy (from clip-anytorch->k-diffusion->TTS)\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of dctorch to determine which version is compatible with other requirements. This could take a while.\n","Collecting dctorch (from k-diffusion->TTS)\n","  Obtaining dependency information for dctorch from https://files.pythonhosted.org/packages/61/ce/14eb8358ce6698ec48d6dfcdff2a1f2978e0fca67a06f890ee17149bc492/dctorch-0.1.1-py3-none-any.whl.metadata\n","  Downloading dctorch-0.1.1-py3-none-any.whl.metadata (607 bytes)\n","  Downloading dctorch-0.1.0-py3-none-any.whl (2.3 kB)\n","Collecting clean-fid (from k-diffusion->TTS)\n","  Downloading clean_fid-0.1.34-py3-none-any.whl (26 kB)\n","Collecting requests (from transformers==4.33.*->TTS)\n","  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet<5,>=3.0.2 (from requests->transformers==4.33.*->TTS)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting idna>=2.0 (from yarl<2.0,>=1.0->aiohttp==3.8.*->TTS)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->transformers==4.33.*->TTS)\n","  Obtaining dependency information for urllib3<1.27,>=1.21.1 from https://files.pythonhosted.org/packages/48/fe/a5c6cc46e9fe9171d7ecf0f33ee7aae14642f8d74baa7af4d7840f9358be/urllib3-1.26.17-py2.py3-none-any.whl.metadata\n","  Downloading urllib3-1.26.17-py2.py3-none-any.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting clean-fid (from k-diffusion->TTS)\n","  Downloading clean_fid-0.1.33-py3-none-any.whl (25 kB)\n","INFO: pip is still looking at multiple versions of dctorch to determine which version is compatible with other requirements. This could take a while.\n","  Downloading clean_fid-0.1.32-py3-none-any.whl (26 kB)\n","  Downloading clean_fid-0.1.31-py3-none-any.whl (24 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading clean_fid-0.1.30-py3-none-any.whl (24 kB)\n","  Downloading clean_fid-0.1.29-py3-none-any.whl (24 kB)\n","  Downloading clean_fid-0.1.28-py3-none-any.whl (23 kB)\n","  Downloading clean_fid-0.1.26-py3-none-any.whl (23 kB)\n","  Downloading clean_fid-0.1.25-py3-none-any.whl (23 kB)\n","  Downloading clean_fid-0.1.24-py3-none-any.whl (23 kB)\n","  Downloading clean_fid-0.1.23-py3-none-any.whl (23 kB)\n","  Downloading clean_fid-0.1.22-py3-none-any.whl (23 kB)\n","  Downloading clean_fid-0.1.21-py3-none-any.whl (23 kB)\n","  Downloading clean_fid-0.1.19-py3-none-any.whl (23 kB)\n","  Downloading clean_fid-0.1.18-py3-none-any.whl (23 kB)\n","  Downloading clean_fid-0.1.17-py3-none-any.whl (23 kB)\n","  Downloading clean_fid-0.1.16-py3-none-any.whl (22 kB)\n","  Downloading clean_fid-0.1.15-py3-none-any.whl (22 kB)\n","  Downloading clean_fid-0.1.14-py3-none-any.whl (22 kB)\n","  Downloading clean_fid-0.1.13-py3-none-any.whl (19 kB)\n","  Downloading clean_fid-0.1.12-py3-none-any.whl (19 kB)\n","  Downloading clean_fid-0.1.11-py3-none-any.whl (19 kB)\n","  Downloading clean_fid-0.1.10-py3-none-any.whl (16 kB)\n","  Downloading clean_fid-0.1.9-py3-none-any.whl (15 kB)\n","  Downloading clean_fid-0.1.8-py3-none-any.whl (16 kB)\n","  Downloading clean_fid-0.1.6-py3-none-any.whl (15 kB)\n","Collecting accelerate (from k-diffusion->TTS)\n","  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/4d/a7/05c67003d659a0035f2b3a8cf389c1d9645865aee84a73ce99ddab16682f/accelerate-0.22.0-py3-none-any.whl.metadata\n","  Downloading accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\n","  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/70/f9/c381bcdd0c3829d723aa14eec8e75c6c377b4ca61ec68b8093d9f35fc7a7/accelerate-0.21.0-py3-none-any.whl.metadata\n","  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n","  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/10/d3/5382aa337d3e67214003a17b06bfc07cf0334356b4e8aaf3b12b0d38c83f/accelerate-0.20.3-py3-none-any.whl.metadata\n","  Downloading accelerate-0.20.3-py3-none-any.whl.metadata (17 kB)\n","  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/47/bd/e89a4ec0df4ae60e204168282c431b04646123d0b304281697c10c39cfa2/accelerate-0.20.2-py3-none-any.whl.metadata\n","  Downloading accelerate-0.20.2-py3-none-any.whl.metadata (17 kB)\n","  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/77/a8/af1e480814d0cccfe60def63471841a365dbd6f94e2d308d9bc1e3db2da2/accelerate-0.20.1-py3-none-any.whl.metadata\n","  Downloading accelerate-0.20.1-py3-none-any.whl.metadata (17 kB)\n","  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/c0/fa/481b16a21ab26077d33645c4ee65d48e227a3c9820a401b37c18b61fef5c/accelerate-0.20.0-py3-none-any.whl.metadata\n","  Downloading accelerate-0.20.0-py3-none-any.whl.metadata (17 kB)\n","  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.17.1-py3-none-any.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.17.0-py3-none-any.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.15.0-py3-none-any.whl (191 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.14.0-py3-none-any.whl (175 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.13.2-py3-none-any.whl (148 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.8/148.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.13.1-py3-none-any.whl (148 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.8/148.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.13.0-py3-none-any.whl (148 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.8/148.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.12.0-py3-none-any.whl (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.0/144.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.11.0-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.1/123.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.10.0-py3-none-any.whl (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.9.0-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.8.0-py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.7.1-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.7.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.6.2-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.6.1-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.6.0-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.5.1-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.5.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading accelerate-0.4.0-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting soxr>=0.3.2 (from librosa==0.10.*->TTS)\n","  Obtaining dependency information for soxr>=0.3.2 from https://files.pythonhosted.org/packages/31/f7/d95b816c47dca6a068305fb7176b8c8d2c94bbc6cce6dcc296c6cf98660f/soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n","  Obtaining dependency information for soxr>=0.3.2 from https://files.pythonhosted.org/packages/c0/ef/12d855b465dc3d85d5c53c666e8963f87557d50bfad68d26cb16348b3747/soxr-0.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading soxr-0.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n","  Downloading soxr-0.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading soxr-0.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading soxr-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading soxr-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pynndescent>=0.5 (from umap-learn==0.5.*->TTS)\n","  Downloading pynndescent-0.5.9.tar.gz (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting contourpy>=1.0.1 (from matplotlib==3.7.*->TTS)\n","  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/f1/6b/e4b0f8708f22dd7c321f87eadbb98708975e115ac6582eb46d1f32197ce6/contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n","  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/aa/55/02c6d24804592b862b38a85c9b3283edc245081390a520ccd11697b6b24f/contourpy-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading contourpy-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n","  Downloading contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading contourpy-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (296 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading contourpy-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.9/295.9 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading contourpy-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (285 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.6/285.6 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading contourpy-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.0/273.0 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading contourpy-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.0/270.0 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading contourpy-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting k-diffusion (from TTS)\n","  Obtaining dependency information for k-diffusion from https://files.pythonhosted.org/packages/20/4a/8e40b44eb854b6c30925d8c4955d94b92c7ba19f92cc5d842694e3aace71/k_diffusion-0.1.0-py3-none-any.whl.metadata\n","  Downloading k_diffusion-0.1.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting rotary-embedding-torch (from k-diffusion->TTS)\n","  Obtaining dependency information for rotary-embedding-torch from https://files.pythonhosted.org/packages/a1/d8/47f3931d984ec96f928e973dcf5cf510768880031d0fd80adc02d962de45/rotary_embedding_torch-0.3.2-py3-none-any.whl.metadata\n","  Downloading rotary_embedding_torch-0.3.2-py3-none-any.whl.metadata (678 bytes)\n","Collecting k-diffusion (from TTS)\n","  Obtaining dependency information for k-diffusion from https://files.pythonhosted.org/packages/57/b2/2175ab0a77e1d17df21f925ab436cd0d330dff2c689db770f330353f83d5/k_diffusion-0.0.16-py3-none-any.whl.metadata\n","  Downloading k_diffusion-0.0.16-py3-none-any.whl.metadata (3.7 kB)\n","Collecting resize-right (from k-diffusion->TTS)\n","  Downloading resize_right-0.0.2-py3-none-any.whl (8.9 kB)\n","Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->TTS) (4.19.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2.31.5)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (1.4.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->TTS) (1.3.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.59.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (3.5)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.7.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.41.2)\n","Collecting trampoline>=0.1.2 (from torchsde->k-diffusion->TTS)\n","  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->k-diffusion->TTS)\n","  Obtaining dependency information for GitPython!=3.1.29,>=1.0.0 from https://files.pythonhosted.org/packages/8a/7e/20f7e45878b5aed34320fbeeae8f78acc806e7bd708d00b1c6e64b016f5b/GitPython-3.1.37-py3-none-any.whl.metadata\n","  Downloading GitPython-3.1.37-py3-none-any.whl.metadata (12 kB)\n","Collecting sentry-sdk>=1.0.0 (from wandb->k-diffusion->TTS)\n","  Obtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/63/25/d22e1e152e4eac10d39d9132d7b5f1ea4bdfa0b9a1d65fc606a7b90aeefb/sentry_sdk-1.32.0-py2.py3-none-any.whl.metadata\n","  Downloading sentry_sdk-1.32.0-py2.py3-none-any.whl.metadata (9.8 kB)\n","Collecting docker-pycreds>=0.4.0 (from wandb->k-diffusion->TTS)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb->k-diffusion->TTS)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb->k-diffusion->TTS)\n","  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/79/e7/54b36be02aee8ad573be68f6f46fd62838735c2f007b22df50eb5e13a20d/setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (1.4.4)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer->TTS) (1.3.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.10.4)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip-anytorch->k-diffusion->TTS) (0.2.8)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS)\n","  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer->TTS) (3.2.2)\n","Downloading TTS-0.17.8-cp310-cp310-manylinux1_x86_64.whl (868 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.1/868.1 kB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m136.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading k_diffusion-0.0.16-py3-none-any.whl (25 kB)\n","Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trainer-0.0.31-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n","Downloading kornia-0.7.0-py2.py3-none-any.whl (705 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.7/705.7 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentry_sdk-1.32.0-py2.py3-none-any.whl (240 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: encodec, umap-learn, bnnumerizer, bnunicodenormalizer, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, pynndescent, gruut, docopt, pathtools\n","  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=d6b61e28f063955cd030c29ebd00efd05826ad17085c971c0b3d22ad4922ce48\n","  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.4-py3-none-any.whl size=86770 sha256=0caa540748cb1ee64f6b9ba9becad8450b24388fef0611936f993add70c37cc2\n","  Stored in directory: /root/.cache/pip/wheels/fb/66/29/199acf5784d0f7b8add6d466175ab45506c96e386ed5dd0633\n","  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5259 sha256=720e3597e0875be67f3103641ba9ad4b0a556eacd3587a1b7fa9c0b058f7e4ef\n","  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n","  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.1.6-py3-none-any.whl size=22779 sha256=d9b3c0e7144c96298fd095817d51c1627ec5d082d4959be7680988d0c49d0579\n","  Stored in directory: /root/.cache/pip/wheels/f4/d7/e9/16732a619cbf5a63fdc9f6e2f9eb5fcf73fa023735237330e9\n","  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104871 sha256=faeba67bbef44534fd8280137a3377a3efb04c20e0038fbbbab853f97c87fb79\n","  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n","  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498181 sha256=8db34062d6faaf4548664639cc0c5d48d612d0ce72e4e18e78e73154f9cb7308\n","  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n","  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297179 sha256=89436b992413d3ed8625a0b8b86bf32afa63a5e7433d4723b42ec5b46fad2af9\n","  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n","  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173797 sha256=7966927842caa147ab755ce2b18d0849be653ae1be5902ec5581ff7943792a4d\n","  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n","  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968767 sha256=099734fc0a6f01dcea8e290ce81e062a2ec62236777fffd387026245514ac1cc\n","  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n","  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55615 sha256=382685467d4ab9f7a60daa33f1fc4cd3a8cebd74c2ae9fad016ff62e9f9daebf\n","  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n","  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75793 sha256=6de74ac7fb12cd8026ee73a080bc04f0993916f64f5c0f71d5afe54935477b8d\n","  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=83fd855119eccbf5db3f710bc536301ade218b3e776813db7a45dddce08809ca\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=3a3ae536f9f68b83b9dcc3ec37b0db38f2f9476b6f0a9b92045bc33da4ed4a65\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built encodec umap-learn bnnumerizer bnunicodenormalizer gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr pynndescent gruut docopt pathtools\n","Installing collected packages: trampoline, tokenizers, resize-right, python-crfsuite, pathtools, jamo, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, tqdm, smmap, setproctitle, sentry-sdk, safetensors, pysbd, pypinyin, packaging, numpy, num2words, networkx, llvmlite, jsonlines, inflect, gruut-ipa, ftfy, einops, docker-pycreds, cython, coqpit, anyascii, numba, huggingface-hub, gitdb, dateparser, transformers, scikit-learn, gruut, GitPython, g2pkk, wandb, pynndescent, librosa, jsonmerge, umap-learn, torchsde, torchdiffeq, kornia, clip-anytorch, clean-fid, accelerate, trainer, k-diffusion, encodec, TTS\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.66.1\n","    Uninstalling tqdm-4.66.1:\n","      Successfully uninstalled tqdm-4.66.1\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 23.2\n","    Uninstalling packaging-23.2:\n","      Successfully uninstalled packaging-23.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.1\n","    Uninstalling networkx-3.1:\n","      Successfully uninstalled networkx-3.1\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.39.1\n","    Uninstalling llvmlite-0.39.1:\n","      Successfully uninstalled llvmlite-0.39.1\n","  Attempting uninstall: inflect\n","    Found existing installation: inflect 7.0.0\n","    Uninstalling inflect-7.0.0:\n","      Successfully uninstalled inflect-7.0.0\n","  Attempting uninstall: cython\n","    Found existing installation: Cython 3.0.3\n","    Uninstalling Cython-3.0.3:\n","      Successfully uninstalled Cython-3.0.3\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.56.4\n","    Uninstalling numba-0.56.4:\n","      Successfully uninstalled numba-0.56.4\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: librosa\n","    Found existing installation: librosa 0.10.1\n","    Uninstalling librosa-0.10.1:\n","      Successfully uninstalled librosa-0.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","plotnine 0.12.3 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.37 TTS-0.17.8 accelerate-0.23.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.6 clean-fid-0.1.35 clip-anytorch-2.5.2 coqpit-0.0.17 cython-0.29.30 dateparser-1.1.8 docker-pycreds-0.4.0 docopt-0.6.2 einops-0.6.1 encodec-0.1.1 ftfy-6.1.1 g2pkk-0.1.2 gitdb-4.0.10 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 huggingface-hub-0.18.0 inflect-5.6.2 jamo-0.4.1 jsonlines-1.2.0 jsonmerge-1.9.2 k-diffusion-0.0.16 kornia-0.7.0 librosa-0.10.0 llvmlite-0.40.1 networkx-2.8.8 num2words-0.5.12 numba-0.57.0 numpy-1.22.0 packaging-23.1 pathtools-0.1.2 pynndescent-0.5.10 pypinyin-0.49.0 pysbd-0.3.4 python-crfsuite-0.9.9 resize-right-0.0.2 safetensors-0.4.0 scikit-learn-1.3.0 sentry-sdk-1.32.0 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.13.3 torchdiffeq-0.2.3 torchsde-0.2.6 tqdm-4.64.1 trainer-0.0.31 trampoline-0.1.2 transformers-4.33.3 umap-learn-0.5.4 unidecode-1.3.7 wandb-0.15.12\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}],"source":["## Install Coqui TTS\n","! pip install -U pip\n","! pip install TTS"]},{"cell_type":"markdown","id":"be5fe49c","metadata":{"id":"be5fe49c"},"source":["## ✅ Data Preparation\n","\n","### **First things first**: we need some data.\n","\n","We're training a Text-to-Speech model, so we need some _text_ and we need some _speech_. Specificially, we want _transcribed speech_. The speech must be divided into audio clips and each clip needs transcription. More details about data requirements such as recording characteristics, background noise and vocabulary coverage can be found in the [🐸TTS documentation](https://tts.readthedocs.io/en/latest/formatting_your_dataset.html).\n","\n","If you have a single audio file and you need to **split** it into clips. It is also important to use a lossless audio file format to prevent compression artifacts. We recommend using **wav** file format.\n","\n","The data format we will be adopting for this tutorial is taken from the widely-used  **LJSpeech** dataset, where **waves** are collected under a folder:\n","\n","<span style=\"color:purple;font-size:15px\">\n","/wavs<br />\n"," &emsp;| - audio1.wav<br />\n"," &emsp;| - audio2.wav<br />\n"," &emsp;| - audio3.wav<br />\n","  ...<br />\n","</span>\n","\n","and a **metadata.csv** file will have the audio file name in parallel to the transcript, delimited by `|`:\n","\n","<span style=\"color:purple;font-size:15px\">\n","# metadata.csv <br />\n","audio1|This is my sentence. <br />\n","audio2|This is maybe my sentence. <br />\n","audio3|This is certainly my sentence. <br />\n","audio4|Let this be your sentence. <br />\n","...\n","</span>\n","\n","In the end, we should have the following **folder structure**:\n","\n","<span style=\"color:purple;font-size:15px\">\n","/MyTTSDataset <br />\n","&emsp;| <br />\n","&emsp;| -> metadata.csv<br />\n","&emsp;| -> /wavs<br />\n","&emsp;&emsp;| -> audio1.wav<br />\n","&emsp;&emsp;| -> audio2.wav<br />\n","&emsp;&emsp;| ...<br />\n","</span>"]},{"cell_type":"markdown","id":"69501a10-3b53-4e75-ae66-90221d6f2271","metadata":{"id":"69501a10-3b53-4e75-ae66-90221d6f2271"},"source":["🐸TTS already provides tooling for the _LJSpeech_. if you use the same format, you can start training your models right away. <br />\n","\n","After you collect and format your dataset, you need to check two things. Whether you need a **_formatter_** and a **_text_cleaner_**. <br /> The **_formatter_** loads the text file (created above) as a list and the **_text_cleaner_** performs a sequence of text normalization operations that converts the raw text into the spoken representation (e.g. converting numbers to text, acronyms, and symbols to the spoken format).\n","\n","If you use a different dataset format then the LJSpeech or the other public datasets that 🐸TTS supports, then you need to write your own **_formatter_** and  **_text_cleaner_**."]},{"cell_type":"markdown","id":"e7f226c8-4e55-48fa-937b-8415d539b17c","metadata":{"id":"e7f226c8-4e55-48fa-937b-8415d539b17c"},"source":["## ⏳️ Loading your dataset\n","Load one of the dataset supported by 🐸TTS.\n","\n","We will start by defining dataset config and setting LJSpeech as our target dataset and define its path.\n"]},{"cell_type":"code","execution_count":2,"id":"b3cb0191-b8fc-4158-bd26-8423c2a8ba66","metadata":{"id":"b3cb0191-b8fc-4158-bd26-8423c2a8ba66","executionInfo":{"status":"ok","timestamp":1697363732596,"user_tz":-330,"elapsed":3340,"user":{"displayName":"VARUN CHINDAGE (RA2111047010224)","userId":"15052075973333773834"}}},"outputs":[],"source":["import os\n","\n","# BaseDatasetConfig: defines name, formatter and path of the dataset.\n","from TTS.tts.configs.shared_configs import BaseDatasetConfig\n","\n","output_path = \"tts_train_dir\"\n","if not os.path.exists(output_path):\n","    os.makedirs(output_path)\n"]},{"cell_type":"code","execution_count":3,"id":"ae6b7019-3685-4b48-8917-c152e288d7e3","metadata":{"id":"ae6b7019-3685-4b48-8917-c152e288d7e3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697364032901,"user_tz":-330,"elapsed":300313,"user":{"displayName":"VARUN CHINDAGE (RA2111047010224)","userId":"15052075973333773834"}},"outputId":"0ccb54b1-404a-4ab9-ac8b-a782935b0fba"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-10-15 09:55:32--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n","Resolving data.keithito.com (data.keithito.com)... 24.199.73.137\n","Connecting to data.keithito.com (data.keithito.com)|24.199.73.137|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2748572632 (2.6G) [text/plain]\n","Saving to: ‘tts_train_dir/LJSpeech-1.1.tar.bz2’\n","\n","tts_train_dir/LJSpe 100%[===================>]   2.56G   116MB/s    in 21s     \n","\n","2023-10-15 09:55:53 (125 MB/s) - ‘tts_train_dir/LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n","\n"]}],"source":["# Download and extract LJSpeech dataset.\n","\n","!wget -O $output_path/LJSpeech-1.1.tar.bz2 https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n","!tar -xf $output_path/LJSpeech-1.1.tar.bz2 -C $output_path"]},{"cell_type":"code","execution_count":4,"id":"76cd3ab5-6387-45f1-b488-24734cc1beb5","metadata":{"id":"76cd3ab5-6387-45f1-b488-24734cc1beb5","executionInfo":{"status":"ok","timestamp":1697364032902,"user_tz":-330,"elapsed":9,"user":{"displayName":"VARUN CHINDAGE (RA2111047010224)","userId":"15052075973333773834"}}},"outputs":[],"source":["dataset_config = BaseDatasetConfig(\n","    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"LJSpeech-1.1/\")\n",")"]},{"cell_type":"markdown","id":"ae82fd75","metadata":{"id":"ae82fd75"},"source":["## ✅ Train a new model\n","\n","Let's kick off a training run 🚀🚀🚀.\n","\n","Deciding on the model architecture you'd want to use is based on your needs and available resources. Each model architecture has it's pros and cons that define the run-time efficiency and the voice quality.\n","We have many recipes under `TTS/recipes/` that provide a good starting point. For this tutorial, we will be using `GlowTTS`."]},{"cell_type":"markdown","id":"f5876e46-2aee-4bcf-b6b3-9e3c535c553f","metadata":{"id":"f5876e46-2aee-4bcf-b6b3-9e3c535c553f"},"source":["We will begin by initializing the model training configuration."]},{"cell_type":"code","execution_count":5,"id":"5483ca28-39d6-49f8-a18e-4fb53c50ad84","metadata":{"id":"5483ca28-39d6-49f8-a18e-4fb53c50ad84","executionInfo":{"status":"ok","timestamp":1697364032902,"user_tz":-330,"elapsed":5,"user":{"displayName":"VARUN CHINDAGE (RA2111047010224)","userId":"15052075973333773834"}}},"outputs":[],"source":["# GlowTTSConfig: all model related values for training, validating and testing.\n","from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n","config = GlowTTSConfig(\n","    batch_size=32,\n","    eval_batch_size=16,\n","    num_loader_workers=4,\n","    num_eval_loader_workers=4,\n","    run_eval=True,\n","    test_delay_epochs=-1,\n","    epochs=100,\n","    text_cleaner=\"phoneme_cleaners\",\n","    use_phonemes=True,\n","    phoneme_language=\"en-us\",\n","    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n","    print_step=25,\n","    print_eval=False,\n","    mixed_precision=True,\n","    output_path=output_path,\n","    datasets=[dataset_config],\n","    save_step=1000,\n",")"]},{"cell_type":"markdown","id":"b93ed377-80b7-447b-bd92-106bffa777ee","metadata":{"id":"b93ed377-80b7-447b-bd92-106bffa777ee"},"source":["Next we will initialize the audio processor which is used for feature extraction and audio I/O."]},{"cell_type":"code","execution_count":6,"id":"b1b12f61-f851-4565-84dd-7640947e04ab","metadata":{"id":"b1b12f61-f851-4565-84dd-7640947e04ab","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697364046385,"user_tz":-330,"elapsed":13487,"user":{"displayName":"VARUN CHINDAGE (RA2111047010224)","userId":"15052075973333773834"}},"outputId":"659a2fed-194e-4e70-eedb-e873664b8efc"},"outputs":[{"output_type":"stream","name":"stdout","text":[" > Setting up Audio Processor...\n"," | > sample_rate:22050\n"," | > resample:False\n"," | > num_mels:80\n"," | > log_func:np.log10\n"," | > min_level_db:-100\n"," | > frame_shift_ms:None\n"," | > frame_length_ms:None\n"," | > ref_level_db:20\n"," | > fft_size:1024\n"," | > power:1.5\n"," | > preemphasis:0.0\n"," | > griffin_lim_iters:60\n"," | > signal_norm:True\n"," | > symmetric_norm:True\n"," | > mel_fmin:0\n"," | > mel_fmax:None\n"," | > pitch_fmin:1.0\n"," | > pitch_fmax:640.0\n"," | > spec_gain:20.0\n"," | > stft_pad_mode:reflect\n"," | > max_norm:4.0\n"," | > clip_norm:True\n"," | > do_trim_silence:True\n"," | > trim_db:45\n"," | > do_sound_norm:False\n"," | > do_amp_to_db_linear:True\n"," | > do_amp_to_db_mel:True\n"," | > do_rms_norm:False\n"," | > db_level:None\n"," | > stats_path:None\n"," | > base:10\n"," | > hop_length:256\n"," | > win_length:1024\n"]}],"source":["from TTS.utils.audio import AudioProcessor\n","ap = AudioProcessor.init_from_config(config)\n","# Modify sample rate if for a custom audio dataset:\n","# ap.sample_rate = 22050\n"]},{"cell_type":"markdown","id":"1d461683-b05e-403f-815f-8007bda08c38","metadata":{"id":"1d461683-b05e-403f-815f-8007bda08c38"},"source":["Next we will initialize the tokenizer which is used to convert text to sequences of token IDs.  If characters are not defined in the config, default characters are passed to the config."]},{"cell_type":"code","execution_count":7,"id":"014879b7-f18d-44c0-b24a-e10f8002113a","metadata":{"id":"014879b7-f18d-44c0-b24a-e10f8002113a","executionInfo":{"status":"ok","timestamp":1697364047940,"user_tz":-330,"elapsed":1562,"user":{"displayName":"VARUN CHINDAGE (RA2111047010224)","userId":"15052075973333773834"}}},"outputs":[],"source":["from TTS.tts.utils.text.tokenizer import TTSTokenizer\n","tokenizer, config = TTSTokenizer.init_from_config(config)"]},{"cell_type":"markdown","id":"df3016e1-9e99-4c4f-94e3-fa89231fd978","metadata":{"id":"df3016e1-9e99-4c4f-94e3-fa89231fd978"},"source":["Next we will load data samples. Each sample is a list of ```[text, audio_file_path, speaker_name]```. You can define your custom sample loader returning the list of samples."]},{"cell_type":"code","execution_count":8,"id":"cadd6ada-c8eb-4f79-b8fe-6d72850af5a7","metadata":{"id":"cadd6ada-c8eb-4f79-b8fe-6d72850af5a7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697364047940,"user_tz":-330,"elapsed":8,"user":{"displayName":"VARUN CHINDAGE (RA2111047010224)","userId":"15052075973333773834"}},"outputId":"e954b024-5f64-4a94-ce67-f78f9b8d0470"},"outputs":[{"output_type":"stream","name":"stdout","text":[" | > Found 13100 files in /content/tts_train_dir/LJSpeech-1.1\n"]}],"source":["from TTS.tts.datasets import load_tts_samples\n","train_samples, eval_samples = load_tts_samples(\n","    dataset_config,\n","    eval_split=True,\n","    eval_split_max_size=config.eval_split_max_size,\n","    eval_split_size=config.eval_split_size,\n",")"]},{"cell_type":"markdown","id":"db8b451e-1fe1-4aa3-b69e-ab22b925bd19","metadata":{"id":"db8b451e-1fe1-4aa3-b69e-ab22b925bd19"},"source":["Now we're ready to initialize the model.\n","\n","Models take a config object and a speaker manager as input. Config defines the details of the model like the number of layers, the size of the embedding, etc. Speaker manager is used by multi-speaker models."]},{"cell_type":"code","execution_count":9,"id":"ac2ffe3e-ad0c-443e-800c-9b076ee811b4","metadata":{"id":"ac2ffe3e-ad0c-443e-800c-9b076ee811b4","executionInfo":{"status":"ok","timestamp":1697364049185,"user_tz":-330,"elapsed":1249,"user":{"displayName":"VARUN CHINDAGE (RA2111047010224)","userId":"15052075973333773834"}}},"outputs":[],"source":["from TTS.tts.models.glow_tts import GlowTTS\n","model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"]},{"cell_type":"markdown","id":"e2832c56-889d-49a6-95b6-eb231892ecc6","metadata":{"id":"e2832c56-889d-49a6-95b6-eb231892ecc6"},"source":["Trainer provides a generic API to train all the 🐸TTS models with all its perks like mixed-precision training, distributed training, etc."]},{"cell_type":"code","execution_count":10,"id":"0f609945-4fe0-4d0d-b95e-11d7bfb63ebe","metadata":{"id":"0f609945-4fe0-4d0d-b95e-11d7bfb63ebe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697364059398,"user_tz":-330,"elapsed":10221,"user":{"displayName":"VARUN CHINDAGE (RA2111047010224)","userId":"15052075973333773834"}},"outputId":"b560727e-3a04-49f1-dbb1-bcf5758acb2b"},"outputs":[{"output_type":"stream","name":"stderr","text":[" > Training Environment:\n"," | > Backend: Torch\n"," | > Mixed precision: True\n"," | > Precision: fp16\n"," | > Current device: 0\n"," | > Num. of GPUs: 1\n"," | > Num. of CPUs: 2\n"," | > Num. of Torch Threads: 1\n"," | > Torch seed: 54321\n"," | > Torch CUDNN: True\n"," | > Torch CUDNN deterministic: False\n"," | > Torch CUDNN benchmark: False\n"," | > Torch TF32 MatMul: False\n"," > Start Tensorboard: tensorboard --logdir=tts_train_dir/run-October-15-2023_10+00AM-0000000\n","\n"," > Model has 28610257 parameters\n"]}],"source":["from trainer import Trainer, TrainerArgs\n","trainer = Trainer(\n","    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",")"]},{"cell_type":"markdown","id":"5b320831-dd83-429b-bb6a-473f9d49d321","metadata":{"id":"5b320831-dd83-429b-bb6a-473f9d49d321"},"source":["### AND... 3,2,1... START TRAINING 🚀🚀🚀"]},{"cell_type":"code","execution_count":null,"id":"d4c07f99-3d1d-4bea-801e-9f33bbff0e9f","metadata":{"id":"d4c07f99-3d1d-4bea-801e-9f33bbff0e9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"937b7070-f6d1-40ac-dbaf-5c15b69b45bd"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n"," --> tts_train_dir/run-October-15-2023_10+00AM-0000000\n"]},{"output_type":"stream","name":"stdout","text":["[*] Pre-computing phonemes...\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 3/12969 [00:00<1:08:04,  3.17it/s]"]},{"output_type":"stream","name":"stdout","text":["ɪnstɛd əv weɪtɪŋ ðɛɹ, ɔzwɔld əpɛɹəntli wɛnt æz fɑɹ əweɪ æz hi kʊd ænd bɔɹdɪd ðə fɚst oʊk klɪf bʌs wɪt͡ʃ keɪm əlɔŋ\n"," [!] Character '͡' not found in the vocabulary. Discarding it.\n"]},{"output_type":"stream","name":"stderr","text":[" 16%|█▌        | 2056/12969 [01:39<10:45, 16.90it/s]"]},{"output_type":"stream","name":"stdout","text":["ɪntu ðə “kɹeɪtɚ” dʌɡ aʊt ɪn ðə mɪdəl, pɔɹ ðə spʌnd͡ʒ, wɔɹm wɔtɚ, ðə məlæsɪz, ænd soʊdə dɪzɑlvd ɪn hɑt wɔtɚ.\n"," [!] Character '“' not found in the vocabulary. Discarding it.\n","ɪntu ðə “kɹeɪtɚ” dʌɡ aʊt ɪn ðə mɪdəl, pɔɹ ðə spʌnd͡ʒ, wɔɹm wɔtɚ, ðə məlæsɪz, ænd soʊdə dɪzɑlvd ɪn hɑt wɔtɚ.\n"," [!] Character '”' not found in the vocabulary. Discarding it.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 12969/12969 [06:07<00:00, 35.31it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\n","\u001b[1m > TRAINING (2023-10-15 10:07:06) \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","> DataLoader initialization\n","| > Tokenizer:\n","\t| > add_blank: False\n","\t| > use_eos_bos: False\n","\t| > use_phonemes: True\n","\t| > phonemizer:\n","\t\t| > phoneme language: en-us\n","\t\t| > phoneme backend: gruut\n","\t| > 3 not found characters:\n","\t| > ͡\n","\t| > “\n","\t| > ”\n","| > Number of instances : 12969\n"," | > Preprocessing samples\n"," | > Max text length: 188\n"," | > Min text length: 13\n"," | > Avg text length: 100.90014650319993\n"," | \n"," | > Max audio length: 222643.0\n"," | > Min audio length: 24499.0\n"," | > Avg audio length: 144984.29755570978\n"," | > Num. instances discarded samples: 0\n"," | > Batch group size: 0.\n"]},{"output_type":"stream","name":"stderr","text":["\n","\u001b[1m   --> TIME: 2023-10-15 10:07:21 -- STEP: 0/406 -- GLOBAL_STEP: 0\u001b[0m\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 11.5  (11.499967098236084)\n","     | > loader_time: 3.2186  (3.218640089035034)\n","\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:07:41 -- STEP: 25/406 -- GLOBAL_STEP: 25\u001b[0m\n","     | > loss: 3.7017674446105957  (3.565107250213623)\n","     | > log_mle: 0.7456618547439575  (0.7429913322130839)\n","     | > loss_dur: 2.9561057090759277  (2.822115929921468)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.6961, device='cuda:0')  (tensor(9.6863, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.0084  (0.8156880187988281)\n","     | > loader_time: 0.0042  (6.5649031639099125)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:08:04 -- STEP: 50/406 -- GLOBAL_STEP: 50\u001b[0m\n","     | > loss: 3.6283936500549316  (3.5583350479602815)\n","     | > log_mle: 0.7438112497329712  (0.7444497764110565)\n","     | > loss_dur: 2.884582281112671  (2.8138852655887603)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.4491, device='cuda:0')  (tensor(10.1442, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.1771  (0.8464875888824462)\n","     | > loader_time: 0.0218  (3.28907253742218)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:08:29 -- STEP: 75/406 -- GLOBAL_STEP: 75\u001b[0m\n","     | > loss: 3.6214752197265625  (3.5548005470862756)\n","     | > log_mle: 0.7506486177444458  (0.7446594485869774)\n","     | > loss_dur: 2.870826482772827  (2.8101410975823033)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.5551, device='cuda:0')  (tensor(10.2493, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.8921  (0.8935771687825521)\n","     | > loader_time: 0.0219  (2.1975934092203775)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:08:55 -- STEP: 100/406 -- GLOBAL_STEP: 100\u001b[0m\n","     | > loss: 3.511307954788208  (3.5441291252772014)\n","     | > log_mle: 0.7496034502983093  (0.7447703897953032)\n","     | > loss_dur: 2.761704444885254  (2.7993587361441716)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.3158, device='cuda:0')  (tensor(10.2744, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.8336  (0.9236869931221008)\n","     | > loader_time: 0.0052  (1.6516875457763667)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:09:22 -- STEP: 125/406 -- GLOBAL_STEP: 125\u001b[0m\n","     | > loss: 3.5148162841796875  (3.5346523761749267)\n","     | > log_mle: 0.7477347254753113  (0.7446393956308778)\n","     | > loss_dur: 2.7670814990997314  (2.790012979507446)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.2298, device='cuda:0')  (tensor(10.2788, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.8963  (0.9532901439666748)\n","     | > loader_time: 0.0182  (1.3243317241668697)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:09:52 -- STEP: 150/406 -- GLOBAL_STEP: 150\u001b[0m\n","     | > loss: 3.542084217071533  (3.5335629531315393)\n","     | > log_mle: 0.7464486360549927  (0.744557414310319)\n","     | > loss_dur: 2.79563570022583  (2.789005540098463)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.4211, device='cuda:0')  (tensor(10.2897, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.6346  (0.9882433239618937)\n","     | > loader_time: 0.0313  (1.1067173878351844)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:10:25 -- STEP: 175/406 -- GLOBAL_STEP: 175\u001b[0m\n","     | > loss: 3.502925395965576  (3.5321802847313157)\n","     | > log_mle: 0.74455326795578  (0.7444689739834177)\n","     | > loss_dur: 2.7583720684051514  (2.7877113125540993)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.2396, device='cuda:0')  (tensor(10.2934, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.3575  (1.0340472425733291)\n","     | > loader_time: 0.0249  (0.9509432016100198)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:10:56 -- STEP: 200/406 -- GLOBAL_STEP: 200\u001b[0m\n","     | > loss: 3.443683624267578  (3.5313250391106856)\n","     | > log_mle: 0.7472482323646545  (0.7444473881470527)\n","     | > loss_dur: 2.6964354515075684  (2.786877648453963)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.1059, device='cuda:0')  (tensor(10.2951, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.8769  (1.0545961916446687)\n","     | > loader_time: 0.0298  (0.8342461597919459)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:11:31 -- STEP: 225/406 -- GLOBAL_STEP: 225\u001b[0m\n","     | > loss: 3.5397462844848633  (3.5276349078777223)\n","     | > log_mle: 0.7427886724472046  (0.744485191134519)\n","     | > loss_dur: 2.796957492828369  (2.7831497136936627)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.2892, device='cuda:0')  (tensor(10.2857, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.862  (1.0915731398264572)\n","     | > loader_time: 0.0214  (0.7435783492194278)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:12:06 -- STEP: 250/406 -- GLOBAL_STEP: 250\u001b[0m\n","     | > loss: 3.6077842712402344  (3.5265438278516132)\n","     | > log_mle: 0.745476484298706  (0.744550595929225)\n","     | > loss_dur: 2.8623077869415283  (2.781993225216865)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.3945, device='cuda:0')  (tensor(10.2796, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.2355  (1.1196227397918705)\n","     | > loader_time: 0.0257  (0.670828538894653)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:12:45 -- STEP: 275/406 -- GLOBAL_STEP: 275\u001b[0m\n","     | > loss: 3.5303633213043213  (3.525669877934006)\n","     | > log_mle: 0.746856153011322  (0.7443356212579977)\n","     | > loss_dur: 2.7835071086883545  (2.7813342481289265)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.2785, device='cuda:0')  (tensor(10.2728, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.8966  (1.1597513684359468)\n","     | > loader_time: 0.0132  (0.6114615431698883)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:13:23 -- STEP: 300/406 -- GLOBAL_STEP: 300\u001b[0m\n","     | > loss: 3.50576114654541  (3.5236019931990517)\n","     | > log_mle: 0.7439934015274048  (0.7442500755704681)\n","     | > loss_dur: 2.761767864227295  (2.7793519110515197)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.1377, device='cuda:0')  (tensor(10.2609, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 2.4398  (1.185750440756481)\n","     | > loader_time: 0.0445  (0.5621558729807534)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:14:04 -- STEP: 325/406 -- GLOBAL_STEP: 325\u001b[0m\n","     | > loss: 3.4584474563598633  (3.5204282336764856)\n","     | > log_mle: 0.7448593378067017  (0.7441223759499805)\n","     | > loss_dur: 2.713588237762451  (2.776305851860652)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.0071, device='cuda:0')  (tensor(10.2454, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.3233  (1.219282933015091)\n","     | > loader_time: 0.0211  (0.5205333416278544)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:14:48 -- STEP: 350/406 -- GLOBAL_STEP: 350\u001b[0m\n","     | > loss: 3.4953460693359375  (3.519249141216277)\n","     | > log_mle: 0.7404838800430298  (0.7440331739537854)\n","     | > loss_dur: 2.7548623085021973  (2.775215962353874)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.0869, device='cuda:0')  (tensor(10.2316, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.2714  (1.2556647498267055)\n","     | > loader_time: 0.0071  (0.48464382444109194)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:15:34 -- STEP: 375/406 -- GLOBAL_STEP: 375\u001b[0m\n","     | > loss: 3.505479335784912  (3.5160148124172257)\n","     | > log_mle: 0.7382793426513672  (0.7438656055763976)\n","     | > loss_dur: 2.767199993133545  (2.7721492029216184)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(10.0118, device='cuda:0')  (tensor(10.2138, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.2979  (1.2931625061035175)\n","     | > loader_time: 0.0084  (0.4537235209147132)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:16:20 -- STEP: 400/406 -- GLOBAL_STEP: 400\u001b[0m\n","     | > loss: 3.4846487045288086  (3.512581866215436)\n","     | > log_mle: 0.7408367395401001  (0.7438094210930359)\n","     | > loss_dur: 2.743811845779419  (2.7687724406902596)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.9216, device='cuda:0')  (tensor(10.1945, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.0275  (1.327296656370165)\n","     | > loader_time: 0.0064  (0.42652409136295283)\n","\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","> DataLoader initialization\n","| > Tokenizer:\n","\t| > add_blank: False\n","\t| > use_eos_bos: False\n","\t| > use_phonemes: True\n","\t| > phonemizer:\n","\t\t| > phoneme language: en-us\n","\t\t| > phoneme backend: gruut\n","\t| > 3 not found characters:\n","\t| > ͡\n","\t| > “\n","\t| > ”\n","| > Number of instances : 131\n"," | > Preprocessing samples\n"," | > Max text length: 174\n"," | > Min text length: 20\n"," | > Avg text length: 100.76335877862596\n"," | \n"," | > Max audio length: 222643.0\n"," | > Min audio length: 34739.0\n"," | > Avg audio length: 144033.41221374046\n"," | > Num. instances discarded samples: 0\n"," | > Batch group size: 0.\n"," | > Synthesizing test sentences.\n"]},{"output_type":"stream","name":"stderr","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time: 0.019709676504135132 \u001b[0m(+0)\n","     | > avg_loss: 3.471115231513977 \u001b[0m(+0)\n","     | > avg_log_mle: 0.7400035634636879 \u001b[0m(+0)\n","     | > avg_loss_dur: 2.7311116456985474 \u001b[0m(+0)\n","\n"," > BEST MODEL : tts_train_dir/run-October-15-2023_10+00AM-0000000/best_model_406.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 1/100\u001b[0m\n"," --> tts_train_dir/run-October-15-2023_10+00AM-0000000\n","\n","\u001b[1m > TRAINING (2023-10-15 10:16:47) \u001b[0m\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:17:05 -- STEP: 19/406 -- GLOBAL_STEP: 425\u001b[0m\n","     | > loss: 3.422649621963501  (3.49613440664191)\n","     | > log_mle: 0.7403563857078552  (0.7384938785904333)\n","     | > loss_dur: 2.682293176651001  (2.75764052491439)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.7046, device='cuda:0')  (tensor(9.7303, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.6468  (0.8093441034618177)\n","     | > loader_time: 0.0103  (0.013113260269165039)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:17:27 -- STEP: 44/406 -- GLOBAL_STEP: 450\u001b[0m\n","     | > loss: 3.358708620071411  (3.4609380147673865)\n","     | > log_mle: 0.7433619499206543  (0.7402878322384574)\n","     | > loss_dur: 2.615346670150757  (2.7206501852382314)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.4807, device='cuda:0')  (tensor(9.7085, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.5513  (0.8179990107362921)\n","     | > loader_time: 0.0232  (0.01347406343980269)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:17:50 -- STEP: 69/406 -- GLOBAL_STEP: 475\u001b[0m\n","     | > loss: 3.4802000522613525  (3.456480002057725)\n","     | > log_mle: 0.7477297782897949  (0.7407880667327107)\n","     | > loss_dur: 2.7324702739715576  (2.7156919396441914)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.6864, device='cuda:0')  (tensor(9.7029, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.4196  (0.8518254134965979)\n","     | > loader_time: 0.0155  (0.013718428819075874)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:18:14 -- STEP: 94/406 -- GLOBAL_STEP: 500\u001b[0m\n","     | > loss: 3.4112727642059326  (3.443645824777319)\n","     | > log_mle: 0.7416574358940125  (0.7406585134090261)\n","     | > loss_dur: 2.6696152687072754  (2.7029873158069373)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.5484, device='cuda:0')  (tensor(9.6649, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.7133  (0.8821014368787723)\n","     | > loader_time: 0.0053  (0.013504066365830441)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:18:40 -- STEP: 119/406 -- GLOBAL_STEP: 525\u001b[0m\n","     | > loss: 3.419694662094116  (3.4336964302704116)\n","     | > log_mle: 0.7365724444389343  (0.740611968922014)\n","     | > loss_dur: 2.683122158050537  (2.693084464353674)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.4935, device='cuda:0')  (tensor(9.6272, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.8527  (0.909452620674582)\n","     | > loader_time: 0.0296  (0.014033155281002782)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:19:07 -- STEP: 144/406 -- GLOBAL_STEP: 550\u001b[0m\n","     | > loss: 3.3902552127838135  (3.4282364265786276)\n","     | > log_mle: 0.7385606169700623  (0.7403672312696776)\n","     | > loss_dur: 2.6516945362091064  (2.687869197792477)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.3796, device='cuda:0')  (tensor(9.5963, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.8601  (0.9342518548170725)\n","     | > loader_time: 0.0128  (0.014646954006618924)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:19:36 -- STEP: 169/406 -- GLOBAL_STEP: 575\u001b[0m\n","     | > loss: 3.4263663291931152  (3.422485774790747)\n","     | > log_mle: 0.7459862232208252  (0.7401731278769366)\n","     | > loss_dur: 2.68038010597229  (2.682312647971881)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.3468, device='cuda:0')  (tensor(9.5605, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.4811  (0.9640452636064157)\n","     | > loader_time: 0.0215  (0.015366605047643537)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:20:10 -- STEP: 194/406 -- GLOBAL_STEP: 600\u001b[0m\n","     | > loss: 3.3966572284698486  (3.4180667326622403)\n","     | > log_mle: 0.7408866882324219  (0.7399348840885559)\n","     | > loss_dur: 2.6557705402374268  (2.6781318507243688)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.2654, device='cuda:0')  (tensor(9.5280, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.5314  (1.0100286904069566)\n","     | > loader_time: 0.0236  (0.016377278209961568)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:20:41 -- STEP: 219/406 -- GLOBAL_STEP: 625\u001b[0m\n","     | > loss: 3.3005611896514893  (3.411169623675412)\n","     | > log_mle: 0.741776168346405  (0.7398158510526024)\n","     | > loss_dur: 2.5587849617004395  (2.6713537734393125)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.0534, device='cuda:0')  (tensor(9.4904, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.9698  (1.0333439900994852)\n","     | > loader_time: 0.0231  (0.016818503810934825)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:21:16 -- STEP: 244/406 -- GLOBAL_STEP: 650\u001b[0m\n","     | > loss: 3.3682408332824707  (3.4074057281994428)\n","     | > log_mle: 0.7356733083724976  (0.7397423818951749)\n","     | > loss_dur: 2.6325674057006836  (2.667663345571425)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.1597, device='cuda:0')  (tensor(9.4572, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.7714  (1.0666122231327124)\n","     | > loader_time: 0.0419  (0.017663278540626902)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:21:52 -- STEP: 269/406 -- GLOBAL_STEP: 675\u001b[0m\n","     | > loss: 3.295642852783203  (3.4020275449221025)\n","     | > log_mle: 0.7422553300857544  (0.7394598609452799)\n","     | > loss_dur: 2.5533876419067383  (2.6625676837552446)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.8648, device='cuda:0')  (tensor(9.4197, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.2881  (1.0982430397799472)\n","     | > loader_time: 0.0452  (0.0184077986110985)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:22:32 -- STEP: 294/406 -- GLOBAL_STEP: 700\u001b[0m\n","     | > loss: 3.338745594024658  (3.3976605335871386)\n","     | > log_mle: 0.737415611743927  (0.7392472754530355)\n","     | > loss_dur: 2.601330041885376  (2.6584132577286295)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.9314, device='cuda:0')  (tensor(9.3822, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.9393  (1.1372826302132646)\n","     | > loader_time: 0.0244  (0.01954010879101396)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:23:10 -- STEP: 319/406 -- GLOBAL_STEP: 725\u001b[0m\n","     | > loss: 3.2971606254577637  (3.3926751456664275)\n","     | > log_mle: 0.7325209379196167  (0.7390267393058372)\n","     | > loss_dur: 2.5646395683288574  (2.6536484078553775)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.7996, device='cuda:0')  (tensor(9.3446, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 2.3936  (1.166961655721396)\n","     | > loader_time: 0.0158  (0.020063421942970967)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:23:51 -- STEP: 344/406 -- GLOBAL_STEP: 750\u001b[0m\n","     | > loss: 3.317929267883301  (3.3893944343855216)\n","     | > log_mle: 0.7352758646011353  (0.7388223901737571)\n","     | > loss_dur: 2.582653284072876  (2.650572046984074)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.7738, device='cuda:0')  (tensor(9.3081, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.0719  (1.1986244320869448)\n","     | > loader_time: 0.0161  (0.0206579330355622)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:24:36 -- STEP: 369/406 -- GLOBAL_STEP: 775\u001b[0m\n","     | > loss: 3.2607414722442627  (3.384300421246991)\n","     | > log_mle: 0.7325614094734192  (0.7385593405584012)\n","     | > loss_dur: 2.5281801223754883  (2.645741082788483)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.6493, device='cuda:0')  (tensor(9.2679, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.7899  (1.2368813988962153)\n","     | > loader_time: 0.0287  (0.021385193517214556)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:25:23 -- STEP: 394/406 -- GLOBAL_STEP: 800\u001b[0m\n","     | > loss: 3.2831685543060303  (3.3787625792062825)\n","     | > log_mle: 0.7395266890525818  (0.7383530764712903)\n","     | > loss_dur: 2.5436418056488037  (2.6404095053067658)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.5032, device='cuda:0')  (tensor(9.2256, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.5319  (1.2739264723008064)\n","     | > loader_time: 0.0182  (0.021476407341545604)\n","\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n"]},{"output_type":"stream","name":"stdout","text":[" | > Synthesizing test sentences.\n"]},{"output_type":"stream","name":"stderr","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.007081806659698486 \u001b[0m(-0.012627869844436646)\n","     | > avg_loss:\u001b[92m 3.2681176364421844 \u001b[0m(-0.2029975950717926)\n","     | > avg_log_mle:\u001b[92m 0.7327463030815125 \u001b[0m(-0.0072572603821754456)\n","     | > avg_loss_dur:\u001b[92m 2.535371333360672 \u001b[0m(-0.19574031233787537)\n","\n"," > BEST MODEL : tts_train_dir/run-October-15-2023_10+00AM-0000000/best_model_812.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 2/100\u001b[0m\n"," --> tts_train_dir/run-October-15-2023_10+00AM-0000000\n","\n","\u001b[1m > TRAINING (2023-10-15 10:25:53) \u001b[0m\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:26:06 -- STEP: 13/406 -- GLOBAL_STEP: 825\u001b[0m\n","     | > loss: 3.3535561561584473  (3.3669966550973744)\n","     | > log_mle: 0.7249153852462769  (0.7316099221889789)\n","     | > loss_dur: 2.62864089012146  (2.6353867053985596)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.5213, device='cuda:0')  (tensor(8.4941, device='cuda:0'))\n","     | > current_lr: 5e-07 \n","     | > step_time: 0.56  (0.5962065549997183)\n","     | > loader_time: 0.0117  (0.012271954463078426)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:26:27 -- STEP: 38/406 -- GLOBAL_STEP: 850\u001b[0m\n","     | > loss: 3.297109365463257  (3.313841851134049)\n","     | > log_mle: 0.7324427962303162  (0.7329434658351698)\n","     | > loss_dur: 2.564666509628296  (2.5808983664763603)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.2024, device='cuda:0')  (tensor(8.3873, device='cuda:0'))\n","     | > current_lr: 5e-07 \n","     | > step_time: 0.6526  (0.7338540679530093)\n","     | > loader_time: 0.0101  (0.013227814122250206)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:26:50 -- STEP: 63/406 -- GLOBAL_STEP: 875\u001b[0m\n","     | > loss: 3.270778179168701  (3.2928023905981156)\n","     | > log_mle: 0.7296880483627319  (0.7329644258060153)\n","     | > loss_dur: 2.5410900115966797  (2.559837958169362)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.1476, device='cuda:0')  (tensor(8.3013, device='cuda:0'))\n","     | > current_lr: 5e-07 \n","     | > step_time: 0.576  (0.7960218361445835)\n","     | > loader_time: 0.0135  (0.013908075907873728)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:27:14 -- STEP: 88/406 -- GLOBAL_STEP: 900\u001b[0m\n","     | > loss: 3.168240547180176  (3.2783783674240112)\n","     | > log_mle: 0.732292652130127  (0.7327292534438047)\n","     | > loss_dur: 2.435947895050049  (2.545649113980206)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(7.7646, device='cuda:0')  (tensor(8.2175, device='cuda:0'))\n","     | > current_lr: 5e-07 \n","     | > step_time: 0.8198  (0.8412675911729983)\n","     | > loader_time: 0.0149  (0.014772114428606901)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:27:40 -- STEP: 113/406 -- GLOBAL_STEP: 925\u001b[0m\n","     | > loss: 3.226165771484375  (3.262055112197336)\n","     | > log_mle: 0.730765700340271  (0.7322723163967639)\n","     | > loss_dur: 2.4953999519348145  (2.5297827973829956)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(7.6928, device='cuda:0')  (tensor(8.1195, device='cuda:0'))\n","     | > current_lr: 5e-07 \n","     | > step_time: 0.8939  (0.8785009088769421)\n","     | > loader_time: 0.007  (0.015250102608604769)\n","\n","\n","\u001b[1m   --> TIME: 2023-10-15 10:28:07 -- STEP: 138/406 -- GLOBAL_STEP: 950\u001b[0m\n","     | > loss: 3.2278902530670166  (3.2501699527104693)\n","     | > log_mle: 0.725916862487793  (0.7315298642801202)\n","     | > loss_dur: 2.5019733905792236  (2.518640089726102)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(7.5271, device='cuda:0')  (tensor(8.0265, device='cuda:0'))\n","     | > current_lr: 5e-07 \n","     | > step_time: 0.8513  (0.9094434406446372)\n","     | > loader_time: 0.0251  (0.015246702277142069)\n","\n"]}],"source":["trainer.fit()"]},{"cell_type":"markdown","id":"4cff0c40-2734-40a6-a905-e945a9fb3e98","metadata":{"id":"4cff0c40-2734-40a6-a905-e945a9fb3e98"},"source":["#### 🚀 Run the Tensorboard. 🚀\n","On the notebook and Tensorboard, you can monitor the progress of your model. Also Tensorboard provides certain figures and sample outputs."]},{"cell_type":"code","execution_count":null,"id":"5a85cd3b-1646-40ad-a6c2-49323e08eeec","metadata":{"id":"5a85cd3b-1646-40ad-a6c2-49323e08eeec"},"outputs":[],"source":["!pip install tensorboard\n","!tensorboard --logdir=tts_train_dir"]},{"cell_type":"markdown","id":"9f6dc959","metadata":{"id":"9f6dc959"},"source":["## ✅ Test the model\n","\n","We made it! 🙌\n","\n","Let's kick off the testing run, which displays performance metrics.\n","\n","We're committing the cardinal sin of ML 😈 (aka - testing on our training data) so you don't want to deploy this model into production. In this notebook we're focusing on the workflow itself, so it's forgivable 😇\n","\n","You can see from the test output that our tiny model has overfit to the data, and basically memorized this one sentence.\n","\n","When you start training your own models, make sure your testing data doesn't include your training data 😅"]},{"cell_type":"markdown","id":"99fada7a-592f-4a09-9369-e6f3d82de3a0","metadata":{"id":"99fada7a-592f-4a09-9369-e6f3d82de3a0"},"source":["Let's get the latest saved checkpoint."]},{"cell_type":"code","execution_count":null,"id":"6dd47ed5-da8e-4bf9-b524-d686630d6961","metadata":{"id":"6dd47ed5-da8e-4bf9-b524-d686630d6961"},"outputs":[],"source":["import glob, os\n","output_path = \"tts_train_dir\"\n","ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n","configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"]},{"cell_type":"code","execution_count":null,"id":"dd42bc7a","metadata":{"id":"dd42bc7a"},"outputs":[],"source":[" !tts --text \"Text for TTS\" \\\n","      --model_path $test_ckpt \\\n","      --config_path $test_config \\\n","      --out_path out.wav"]},{"cell_type":"markdown","id":"81cbcb3f-d952-469b-a0d8-8941cd7af670","metadata":{"id":"81cbcb3f-d952-469b-a0d8-8941cd7af670"},"source":["## 📣 Listen to the synthesized wave 📣"]},{"cell_type":"code","execution_count":null,"id":"e0000bd6-6763-4a10-a74d-911dd08ebcff","metadata":{"id":"e0000bd6-6763-4a10-a74d-911dd08ebcff"},"outputs":[],"source":["import IPython\n","IPython.display.Audio(\"out.wav\")"]},{"cell_type":"markdown","id":"13914401-cad1-494a-b701-474e52829138","metadata":{"id":"13914401-cad1-494a-b701-474e52829138"},"source":["## 🎉 Congratulations! 🎉 You now have trained your first TTS model!\n","Follow up with the next tutorials to learn more advanced material."]},{"cell_type":"code","execution_count":null,"id":"950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7","metadata":{"id":"950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[{"file_id":"https://github.com/coqui-ai/TTS/blob/dev/notebooks/Tutorial_2_train_your_first_TTS_model.ipynb","timestamp":1697363435711}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}